{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07321128-7a9a-480d-a151-406c5b809014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 09:41:44.620689: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# from mtcnn import MTCNN\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "from torch import autocast\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from diffusers import (\n",
    "    StableDiffusionPipeline, AutoencoderKL,\n",
    "    UNet2DConditionModel, PNDMScheduler, LMSDiscreteScheduler\n",
    ")\n",
    "from diffusers.schedulers.scheduling_ddim import DDIMScheduler\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, CLIPProcessor, CLIPModel\n",
    "from tqdm.auto import tqdm\n",
    "from huggingface_hub import notebook_login\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "from PIL import Image, ImageDraw\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import signal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os \n",
    "from tqdm import tqdm \n",
    "\n",
    "device = 'cuda'\n",
    "PATH = 'dataset//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e6baba-9842-4143-9dfd-f2294dc1c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(pil_image):\n",
    "    pil_image = pil_image.convert(\"RGB\")\n",
    "    processing_pipe = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ])\n",
    "    tensor = processing_pipe(pil_image)\n",
    "    tensor = tensor.reshape(1, 3, 512, 512)\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def encode_vae(img):\n",
    "    img_tensor = preprocess(img)\n",
    "    with torch.no_grad():\n",
    "        diag_gaussian_distrib_obj = vae.encode(img_tensor.to(device), return_dict=False)\n",
    "        img_latent = diag_gaussian_distrib_obj[0].sample().detach().cpu()\n",
    "        img_latent *= 0.18215\n",
    "    return img_latent\n",
    "\n",
    "#Загрузка сети, создание функции генерации по вектору \n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    'runwayml/stable-diffusion-v1-5', \n",
    "    subfolder='vae',\n",
    "    use_auth_token=True\n",
    ")\n",
    "vae = vae.to(device)\n",
    "# dict(vae.config)\n",
    "\n",
    "def decode_latents(latents):\n",
    "    latents = 1 / 0.18215 * latents\n",
    "\n",
    "    with torch.no_grad():\n",
    "        images = vae.decode(latents)['sample']\n",
    "\n",
    "    images = (images / 2 + 0.5).clamp(0, 1)\n",
    "    images = images.detach().cpu().permute(0, 2, 3, 1).numpy()\n",
    "    images = (images * 255).round().astype('uint8')\n",
    "    pil_images = [Image.fromarray(image) for image in images]\n",
    "    return pil_images\n",
    "\n",
    "\n",
    "#Функции интерполяции\n",
    "\n",
    "def interpolate(tensor1, tensor2, curve, num_points):\n",
    "    points = []\n",
    "    for i in range(num_points):\n",
    "        alpha = i / (num_points - 1)\n",
    "        weight = curve(alpha)\n",
    "        seem_chaos = 0.2\n",
    "        tensor = ((1 - weight) * tensor1) + weight * tensor2\n",
    "        #1!!!!!\n",
    "#         tensor+=torch.randn(1,4,64,64)*seem_chaos\n",
    "        points.append(tensor)\n",
    "    return points\n",
    "\n",
    "def sine_curve(alpha):\n",
    "    return 0.5 * (np.sin(np.pi * (alpha - 0.5)) + 1)\n",
    "\n",
    "\n",
    "\n",
    "#Функция для создания синуса с возможностью контролировать в простратсве \n",
    "def shifted_sin(x, x_offset=0.94, y_offset=0,freq=-4):\n",
    "    return np.sin(freq * x - x_offset) + y_offset\n",
    "\n",
    "#Функция для создания синуса с шумом и сглажииванием \n",
    "def sine_curve_with_smooth_noise(alpha, noise_scale=0, filter_alpha=0.8):\n",
    "    noise = np.random.normal(scale=noise_scale, size=(1))\n",
    "    smoothed_noise = signal.lfilter([1 - filter_alpha], [1, -filter_alpha], noise)\n",
    "    return (0.5 * (np.sin(np.pi * (alpha - 0.5)) + 1) + smoothed_noise)[0]\n",
    "\n",
    "#Функция для модулирования сигнала \n",
    "def modulation_two_sin(x):\n",
    "    return sine_curve_with_smooth_noise(x)*shifted_sin(x)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90bb2d-c828-427d-abe1-5dc4f203520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lattens = []\n",
    "# for file in tqdm(files):\n",
    "#     img = Image.open(f\"dataset/{file}\")\n",
    "#     img = img.resize((512,512))\n",
    "#     lattens.append(encode_vae(img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2890efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Строим график функции интерполяции  если нужно \n",
    "# alphas= np.linspace(0, 1 , 100)\n",
    "\n",
    "# y = [modulation_two_sin(alpha) for alpha in alphas]\n",
    "\n",
    "# plt.plot(alphas, y)\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# plt.title('y_max= ' + str(y[-1]))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e3eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# тест картинки после множественного денойзинга \n",
    "# img = decode_latents(lattens[0].to(device))\n",
    "# display(img[0])\n",
    "# for i in range(10):\n",
    "#     vector1=  encode_vae(img[0])\n",
    "#     img = decode_latents(vector1.to(device))\n",
    "#     print(i)\n",
    "#     display(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fce8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Тест интерполяции 2 векторов по нашей кривой \n",
    "# tensor1 = vector1\n",
    "# tensor2 = vector2\n",
    "# points = interpolate(tensor1, tensor2, sine_curve_with_smooth_noise, 20)\n",
    "# for i in points:\n",
    "#     img = decode_latents(i.to(device))\n",
    "#     display(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628f3c40",
   "metadata": {},
   "source": [
    "## Начало конвеера \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dcda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Первое я бы расчитал все вектора которые нужны и сохранил бы в picke \n",
    "#Пердполагаемый формат данных {\"img_name\":[векторы от 0 до 20 ]}\n",
    "#После находим стартовый вектор у которого больше всего соседий начинаем с него pipeline \n",
    "#Берем все его вектора после находим ближайший вектор к последнему для него \n",
    "#Берем все вектора у соседа задонаперед с срезом первых пяти \n",
    "#Далее находим у 5 соседа "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ffa469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                        | 0/68 [00:00<?, ?it/s]\n",
      "  0%|                                                                        | 0/20 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|███▏                                                            | 1/20 [00:01<00:26,  1.41s/it]\u001b[A\n",
      " 10%|██████▍                                                         | 2/20 [00:02<00:25,  1.41s/it]\u001b[A\n",
      " 15%|█████████▌                                                      | 3/20 [00:04<00:24,  1.41s/it]\u001b[A\n",
      " 20%|████████████▊                                                   | 4/20 [00:06<00:24,  1.53s/it]\u001b[A\n",
      "  0%|                                                                        | 0/68 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 │   </span>lattens.append(encode_vae(img))                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 │   </span>img = decode_latents(lattens[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].to(device))                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tqdm(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(NUM_ITERATION_DENOISING)):                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>15 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>vector =  encode_vae(img[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   │   </span>img = decode_latents(vector.to(device))                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 │   │   </span>lattens.append(vector)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 │   </span>main_lattens [file] = lattens                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">encode_vae</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 │   </span>img_tensor = preprocess(img)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   │   </span>diag_gaussian_distrib_obj = vae.encode(img_tensor.to(device), return_dict=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>)    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>17 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>img_latent = diag_gaussian_distrib_obj[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>].sample().detach().cpu()                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 │   │   </span>img_latent *= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.18215</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">19 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> img_latent                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   \u001b[0mlattens.append(encode_vae(img))                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   \u001b[0mimg = decode_latents(lattens[\u001b[94m0\u001b[0m].to(device))                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m tqdm(\u001b[96mrange\u001b[0m(NUM_ITERATION_DENOISING)):                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m15 \u001b[2m│   │   \u001b[0mvector =  encode_vae(img[\u001b[94m0\u001b[0m])                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0mimg = decode_latents(vector.to(device))                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0mlattens.append(vector)                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   \u001b[0mmain_lattens [file] = lattens                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mencode_vae\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   \u001b[0mimg_tensor = preprocess(img)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0mdiag_gaussian_distrib_obj = vae.encode(img_tensor.to(device), return_dict=\u001b[94mFalse\u001b[0m)    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m17 \u001b[2m│   │   \u001b[0mimg_latent = diag_gaussian_distrib_obj[\u001b[94m0\u001b[0m].sample().detach().cpu()                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   │   \u001b[0mimg_latent *= \u001b[94m0.18215\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m19 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m img_latent                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Шумоподавление картинки и подача самой себя 20 раз\n",
    "#Сохранение векторов на кажом шаге \n",
    "NUM_ITERATION_DENOISING=20\n",
    "files = os.listdir(PATH)\n",
    "main_lattens = {}\n",
    "\n",
    "for file in tqdm(files):\n",
    "    lattens=[]\n",
    "    img = Image.open(f\"{PATH}{file}\")\n",
    "    img = img.resize((512,512))\n",
    "    #первый вектор \n",
    "    lattens.append(encode_vae(img))\n",
    "    img = decode_latents(lattens[0].to(device))\n",
    "    for i in tqdm(range(NUM_ITERATION_DENOISING)):\n",
    "        vector =  encode_vae(img[0])\n",
    "        img = decode_latents(vector.to(device))\n",
    "        lattens.append(vector)\n",
    "    main_lattens [file] = lattens\n",
    "\n",
    "with open('oleg.pickle', 'wb') as f:\n",
    "    pickle.dump(main_lattens, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17fa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Загружаем заранее посчитанные вектора и с ними и работаем \n",
    "with open('main_lattens.pickle', 'rb') as f:\n",
    "    main_lattens = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53567620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_vector(data):\n",
    "    \"\"\"\n",
    "    Находит вектор, ближайший к центру группы векторов.\n",
    "    С него начнем \n",
    "    Аргументы:\n",
    "    data -- numpy массив данных размерности (n_samples, 1, 4, 64, 64).\n",
    "    Возвращает:\n",
    "    closest_vector -- numpy массив размерности (1, 4, 64, 64), представляющий\n",
    "    вектор, ближайший к центру группы векторов.\n",
    "    \"\"\"\n",
    "    # Вычисляем центр группы векторов\n",
    "    center = np.mean(data, axis=0)\n",
    "    # Приводим данные и центр к формату (n_samples, n_features), где n_features = 1*4*64*64 = 16384\n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "    center = center.reshape(1, -1)\n",
    "    # Вычисляем расстояние между центром и каждым вектором\n",
    "    distances = np.linalg.norm(data - center, axis=1)\n",
    "    # Находим индекс вектора с минимальным расстоянием до центра\n",
    "    min_distance_idx = np.argmin(distances)\n",
    "    # Получаем вектор с минимальным расстоянием до центра\n",
    "    closest_vector = data[min_distance_idx, :]\n",
    "    # Приводим вектор обратно к исходному формату (1, 4, 64, 64)\n",
    "    closest_vector = closest_vector.reshape(1, 4, 64, 64)\n",
    "    return closest_vector, min_distance_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5a950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chose_start_vectors = []\n",
    "for i in main_lattens.keys():\n",
    "#     chose_start_vectors[i]=main_lattens[i][0][0].numpy()\n",
    "    chose_start_vectors.append(main_lattens[i][0][0].numpy()) \n",
    "#     chose_start_vectors.append(main_lattens[i][0])\n",
    "x = np.array(chose_start_vectors)\n",
    "# find_closest_vector(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091335f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf981d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_nearest_neighbors(query_vector, pool_vectors, k=5):\n",
    "    \"\"\"\n",
    "    Находит k ближайших соседей к заданному вектору в пуле векторов.\n",
    "    \n",
    "    Аргументы:\n",
    "    query_vector -- numpy массив размерности (1, 4, 64, 64), представляющий\n",
    "    вектор запроса.\n",
    "    pool_vectors -- numpy массив размерности (n_samples, 1, 4, 64, 64), представляющий\n",
    "    пул векторов.\n",
    "    k -- количество ближайших соседей, которые нужно найти. По умолчанию k=5.\n",
    "    \n",
    "    Возвращает:\n",
    "    indices -- numpy массив размерности (k,), содержащий индексы k ближайших\n",
    "    соседей в пуле векторов.\n",
    "    distances -- numpy массив размерности (k,), содержащий расстояния от\n",
    "    запроса до каждого из k ближайших соседей.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Приводим вектор запроса и пул векторов к формату (n_samples, n_features),\n",
    "    # где n_features = 1*4*64*64 = 16384\n",
    "    query_vector = query_vector.reshape(1, -1)\n",
    "    pool_vectors = pool_vectors.reshape(pool_vectors.shape[0], -1)\n",
    "\n",
    "    # Вычисляем расстояние между запросом и каждым вектором в пуле\n",
    "    distances = np.linalg.norm(pool_vectors - query_vector, axis=1)\n",
    "\n",
    "    # Находим индексы k векторов с наименьшим расстоянием до запроса\n",
    "    indices = np.argsort(distances)[:k]\n",
    "\n",
    "    # Получаем расстояния до k ближайших соседей\n",
    "    distances = distances[indices]\n",
    "\n",
    "    return indices, distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceae5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Новый подход \n",
    "# У нас есть 2 массива 5iter с ключем изображения  и 20iter с ключем изображения \n",
    "#Сперва находим ближайший к стартовому в 5iter, берем все кадры в animation_frame \n",
    "#Последний используем для нахождения ближайшего в 20iter разворачиваем его  и кладем в animation_frame \n",
    "#После добовляем интерполяцию \n",
    "DENOISING_TRASHHOLD=5\n",
    "twenty_iter = {}\n",
    "five_iter = {}\n",
    "for key in main_lattens:\n",
    "    five_iter[key] = main_lattens[key][DENOISING_TRASHHOLD].numpy()\n",
    "    twenty_iter[key] = main_lattens[key][-1].numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4dead12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Находим ключ ближайшего фото для start_vector\n",
    "def key_nearest_vector_dict(vec,target_dict):\n",
    "    index,_ = find_nearest_neighbors(vec,np.array(list(target_dict.values())))\n",
    "    return list(target_dict.keys())[index[0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c210fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(chose_start_vectors)\n",
    "start_vector , _ = find_start_vector(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc2a202",
   "metadata": {},
   "source": [
    "### Основной блок анимации "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b1facd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|██████████████████████████████▌                               | 33/67 [00:00<00:00, 333.55it/s]\n"
     ]
    }
   ],
   "source": [
    "DENOISING_TRASHHOLD=5\n",
    "twenty_iter = {}\n",
    "five_iter = {}\n",
    "for key in main_lattens:\n",
    "    five_iter[key] = main_lattens[key][DENOISING_TRASHHOLD].numpy()\n",
    "    twenty_iter[key] = main_lattens[key][-1].numpy()\n",
    "\n",
    "\n",
    "animation_list = []\n",
    "new_start_vec = start_vector\n",
    "for i in tqdm(range(len(five_iter)-1)):\n",
    "    \n",
    "    key = key_nearest_vector_dict(new_start_vec,five_iter)\n",
    "    \n",
    "\n",
    "   \n",
    "    #Берем все следующии кадры \n",
    "    new_frames = main_lattens[key][DENOISING_TRASHHOLD:]\n",
    "    \n",
    "    #Место для интерполяции \n",
    "    # start_vector вместе  new_frames[0]\n",
    "    points = interpolate(new_start_vec, new_frames[0].numpy(),\n",
    "                         sine_curve,16)\n",
    "    for i in points[::-1]:\n",
    "        new_frames.insert(0,i)\n",
    "    \n",
    "    #Добовляем в \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Удаляем из всех словарей старый ключ \n",
    "    del five_iter[key]\n",
    "    del twenty_iter[key]\n",
    "\n",
    "    #нАзначаем новый вектор \n",
    "    new_start_vec = new_frames[-1].numpy()\n",
    "    #добовляем new_frames в список кадров анимации \n",
    "    [animation_list.append(i) for i in new_frames]\n",
    "    \n",
    "    if len(five_iter) == 0:\n",
    "        break\n",
    "    \n",
    "    key = key_nearest_vector_dict(new_start_vec,twenty_iter)\n",
    "\n",
    "    #Добавляем все кадры с новым ключем срезая на 5 и переворачивая последовательность \n",
    "    new_frames = list(reversed(main_lattens[key][DENOISING_TRASHHOLD:]))\n",
    "    \n",
    "    points = interpolate(new_start_vec, new_frames[0].numpy(),\n",
    "                         sine_curve, 16)\n",
    "    for i in points[::-1]:\n",
    "        new_frames.insert(0,i)\n",
    "    \n",
    "    #\n",
    "    del five_iter[key]\n",
    "    del twenty_iter[key]\n",
    "    \n",
    "    #нАзначаем новый вектор \n",
    "    new_start_vec = new_frames[-1].numpy()\n",
    "\n",
    "    #добовляем new_frames в список кадров анимации \n",
    "    [animation_list.append(i) for i in new_frames]\n",
    "    if len(five_iter) == 0:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5370315",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>get_ipython().system(<span style=\"color: #808000; text-decoration-color: #808000\">'rm -rf output/'</span>)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>get_ipython().system(<span style=\"color: #808000; text-decoration-color: #808000\">'mkdir output'</span>)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 show_animation_list(animation_list)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'show_animation_list'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mget_ipython().system(\u001b[33m'\u001b[0m\u001b[33mrm -rf output/\u001b[0m\u001b[33m'\u001b[0m)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mget_ipython().system(\u001b[33m'\u001b[0m\u001b[33mmkdir output\u001b[0m\u001b[33m'\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 show_animation_list(animation_list)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'show_animation_list'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!rm -rf output/\n",
    "!mkdir output\n",
    "show_animation_list(animation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7cdc8145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "Input #0, image2, from '/home/amigutskiy/Workbench/art_poster/output/frame_%d.jpg':\n",
      "  Duration: 00:03:01.33, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 512x512 [SAR 1:1 DAR 1:1], 12 fps, 12 tbr, 12 tbn, 12 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x5620d50ff8c0] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0m\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mprofile High, level 2.2\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0m264 - core 155 r2917 0a84d98 - H.264/MPEG-4 AVC codec - Copyleft 2003-2018 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=6 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=12 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'final_SD.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.29.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 512x512 [SAR 1:1 DAR 1:1], q=-1--1, 12 fps, 12288 tbn, 12 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.54.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame= 2176 fps=108 q=-1.0 Lsize=   79843kB time=00:03:01.08 bitrate=3612.0kbits/s speed=8.95x    \n",
      "video:79826kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.021350%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mframe I:9     Avg QP:15.83  size:105934\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mframe P:1663  Avg QP:18.56  size: 44929\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mframe B:504   Avg QP:20.80  size: 12046\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mconsecutive B-frames: 66.2%  3.6% 15.7% 14.5%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mmb I  I16..4:  1.6% 56.7% 41.7%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mmb P  I16..4:  0.0%  2.2%  3.1%  P16..4: 27.5% 35.1% 31.3%  0.0%  0.0%    skip: 0.8%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mmb B  I16..4:  0.0%  0.1%  0.6%  B16..8: 12.0%  2.9%  2.4%  direct:23.0%  skip:59.0%  L0:22.5% L1:12.6% BI:64.9%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0m8x8 transform intra:41.3% inter:49.7%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mcoded y,uvDC,uvAC intra: 99.7% 94.9% 86.5% inter: 79.4% 75.6% 59.2%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mi16 v,h,dc,p:  4%  6% 24% 67%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 11% 21%  7%  8% 12%  7%  9%  9%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20%  9% 10%  7% 10% 15%  8% 10%  9%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mi8c dc,h,v,p: 55% 14% 19% 12%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mWeighted P-Frames: Y:94.8% UV:92.5%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mref P L0: 68.5% 20.3% 11.1%  0.1%  0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mref B L0: 99.4%  0.6%  0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mref B L1: 100.0%  0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5620d50a0d00] \u001b[0mkb/s:3606.22\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -y -framerate 12 -i /home/amigutskiy/Workbench/art_poster/output/frame_%d.jpg  -c:v libx264 -pix_fmt yuv420p -crf 18 final_SD.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d988fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"final_SD.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Поставил синсус\n",
    "from IPython.display import Video\n",
    "Video(filename=\"final_SD.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b8d21b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"final_30.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Поставил синсус\n",
    "Video(filename=\"final_30.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cb5a6bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"final_15.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Поставил синсус\n",
    "Video(filename=\"final_15.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a4ee59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нужно сделать возможность сохранения \n",
    "def show_animation_list(animation_list, save=True):\n",
    "    for count, frame in enumerate(tqdm(animation_list)):\n",
    "        vec = torch.tensor(frame)\n",
    "        img = decode_latents(vec.to(device))[0]\n",
    "        if save:\n",
    "            img.save(f\"output/frame_{str(count)}.jpg\",quality=100)\n",
    "        if not save:\n",
    "            display(img)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7b0dde9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                 | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 show_animation_list(<span style=\"color: #808000; text-decoration-color: #808000\">\"wer\"</span>)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">show_animation_list</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 # Нужно сделать возможность сохранения </span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">show_animation_list</span>(animation_list, save=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> count, frame <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(tqdm(animation_list)):                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 4 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>vec = torch.tensor(frame)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 │   │   </span>img = decode_latents(vec.to(device))[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> save:                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"ок\"</span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">new</span><span style=\"font-weight: bold\">()</span>: invalid data type <span style=\"color: #008000; text-decoration-color: #008000\">'str'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 show_animation_list(\u001b[33m\"\u001b[0m\u001b[33mwer\u001b[0m\u001b[33m\"\u001b[0m)                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mshow_animation_list\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[2m# Нужно сделать возможность сохранения \u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mshow_animation_list\u001b[0m(animation_list, save=\u001b[94mTrue\u001b[0m):                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m count, frame \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(tqdm(animation_list)):                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 4 \u001b[2m│   │   \u001b[0mvec = torch.tensor(frame)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   │   \u001b[0mimg = decode_latents(vec.to(device))[\u001b[94m0\u001b[0m]                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m save:                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mок\u001b[0m\u001b[33m\"\u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35mnew\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m: invalid data type \u001b[32m'str'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_animation_list(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68c7c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_animation_list(animation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Фильтруем данные для упрощения беру у всех [5:] \n",
    "#Если захочишь добавить в начле больше оригинала сделай это руками\n",
    "DENOISING_TRASHHOLD=4\n",
    "big_vectors_bag = []\n",
    "for values in tqdm(main_lattens.values()):\n",
    "    #Срезаю 5 первых генераций как не интересные\n",
    "    for frame in values[DENOISING_TRASHHOLD:]:\n",
    "        big_vectors_bag.append(frame.numpy())\n",
    "#     new_lst = [elem for sublist in lst for elem in sublist]\n",
    "    \n",
    "big_vectors_bag = np.array(big_vectors_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d458ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Попытка расчета анимации\n",
    "#Результат большой корзины мне не нрав, нужно искать ближайший только среди чистых и шумных\n",
    "target_vector = start_vector\n",
    "animation_list = [] \n",
    "test_dist=[]\n",
    "# for i in range(len(big_vectors_bag)):\n",
    "for i in range(100):\n",
    "    #Ищем вектор, добовляем его в лист, удаляем его ищим следующий \n",
    "    indexes, dist = find_nearest_neighbors(target_vector,  big_vectors_bag,k=5)\n",
    "    test_dist.append(dist[0])\n",
    "    target_vector = big_vectors_bag[indexes[0]]\n",
    "    animation_list.append(target_vector)\n",
    "    big_vectors_bag = np.delete(big_vectors_bag,indexes[0],axis=0)\n",
    "    print(indexes)\n",
    "    print(dist)\n",
    "    show_animation_list([target_vector])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a900021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
